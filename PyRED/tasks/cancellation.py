import os
import copy
import time

import numpy
from scipy.stats import pearsonr

from PyRED.files import read_behaviour
from PyRED.tasks.generic import TaskLoader


class CancellationLoader(TaskLoader):
    
    """Class to process files from the RED CancellationTask.
    """
    
    def __init__(self, data_dir, output_path=None, \
            task_name="CancellationTask", task_path=None):
        
        """Initialises a new CancellationLoader instance to read and process
        data from files generated by the RED cancellation tasks.
        
        Arguments
        
        data_dir            -   String. Path to the directory that contains
                                data files that need to be loaded.

        Keyword Arguments
        
        output_path         -   String. Path to the file in which processed
                                data needs to be stored, or None to not write
                                the data to file. Default = None

        task_name           -   String. Name of the task that needs to be
                                present in the data files. The names of data
                                files are assumed to be in the format
                                "taskname_ppname_yyyy-mm-dd-HH-MM-SS"
                                Default = "CancellationTask"

        task_path           -   String. Path to the folder that contains the
                                task's image, and text files with the target
                                and distractor locations; or None to use the
                                task info that is included with this library.
                                Default = None
        """
        
        # Define the default answer_file.
        if task_path is None:
            task_path = os.path.join( \
                os.path.dirname(os.path.abspath(__file__)), task_name)
        # Throw an error if the answer sheet doesn't exist at the expected 
        # location.
        if not os.path.isdir(task_path):
            raise Exception("ERROR: Could not find the answer file at '%s'" % \
                (task_path))

        # Load this task's target and distractor location data.
        self._task = {}
        self._task["imgpath"] = os.path.join(task_path, "task.png")
        for stim in ["target", "distractor"]:
            # Read the text file.
            raw = numpy.loadtxt(os.path.join(task_path, "%ss.txt" % (stim)), \
                unpack=True, dtype=str, delimiter="\t")
            # Convert the raw data into a dict format.
            r = {}
            for i in range(raw.shape[0]):
                try:
                    r[raw[i,0]] = raw[i,1:].astype(float)
                except:
                    r[raw[i,0]] = raw[i,1:]
            # Store the x and y coordinates of this stimulus type.
            self._task[stim] = { \
                "x": numpy.copy(r["x"]), \
                "y": numpy.copy(r["y"]), \
                }

        # Load all data.
        self.load_from_directory(data_dir, task_name)
        self.process_raw_data()
        if not (output_path is None):
            self.write_processed_data_to_file(output_path)


    def load_from_file(self, file_path, delimiter=",", missing=None, \
            auto_typing=True, string_vars=None):
        
        """Loads data from a single file. This function overwrites the parent's
        load_from_file function to allow for the checking of answers.

        Arguments
        
        file_path       -   String. Path to the file that needs to be loaded.
        
        Keyword arguments
        
        delimiter       -   String. Delimiter for the data file. Default = ","
        
        missing         -   List. List of values that code for missing data, or
                            None if no such values exist. Note that all values
                            should be strings, as this is what the data will
                            initially be read as (missing data is converted before
                            auto-typing occurs). Default = None.
        
        auto_typing     -   Bool. When True, variables will automatically be
                            converted to float where possible. Default = True
        
        Returns
        
        data            -   Whatever PyRED.files.read_behaviour returns.
        """
        
        # Load the data from a file.
        raw = read_behaviour(file_path, delimiter=",", missing=None, \
            auto_typing=True, string_vars=["stimulus"])
        
        # If the file is empty, return None.
        if raw is None:
            return None
        
        # Convert time to seconds.
        raw["time"] /= 1000.0
        
        return raw
    
    
    def process_raw_data(self):
        
        """Computes the variables that need to be computed from this task, and
        stores them in the self.data dict. This has one key for every variable
        of interest, and each of these keys points to a NumPy array with shape
        (N,) where N is the number of participants.
        
        The processed data comes from the self.raw dict, so make sure that
        self.load_from_directory is run before this function is.
        """
        
        # Get all participant names, or return straight away if no data was
        # loaded yet.
        if hasattr(self, "raw"):
            participants = self.raw.keys()
            participants.sort()
        else:
            self.data = None
            return
        
        # Count the number of participants.
        n = len(participants)
        
        # Define some variables of interest.
        vor = ["n_stimuli", "n_targets", "n_distractors", "pathlength", "duration", \
            "omissions", "CoC_hor", "CoC_ver", \
            "revisits_tot", "revisits_imm", "revisits_del", \
            "interdist", "interdist_stand", "intertime", "Qscore", \
            "angle_mean", "angle_stand", "bestR", "intersect_tot", "intersect_rate", \
            "first_x", "first_y"]
        # Create a data dict for each variable of interest.
        self.data = {}
        self.data["ppname"] = []
        for var in vor:
            self.data[var] = numpy.zeros(n, dtype=float) * numpy.NaN
        
        # Compute ALL the things!
        for i, ppname in enumerate(participants):

            # Add the participant name.
            self.data["ppname"].append(copy.deepcopy(ppname))
            # Skip empty datasets.
            if self.raw[ppname] is None:
                continue

            # Get the duration of the task in seconds.
            self.data["duration"][i] = self.raw[ppname]["time"][-1]

            # Calculate the total number of stimuli that were clicked.
            self.data["n_stimuli"][i] = len(self.raw[ppname]["stimulus"])

            # Compute the total number of clicked targets.
            self.data["n_targets"][i] = numpy.sum( \
                self.raw[ppname]["stimulus"] == "target")

            # Compute the total number of clicked distractors.
            self.data["n_distractors"][i] = numpy.sum( \
                self.raw[ppname]["stimulus"] == "distractor")

            # Calculate omissions and total revisits.
            self.data["omissions"][i] = 0
            self.data["revisits_tot"][i] = 0
            # Loop through all targets.
            n_targets = len(self._task["target"]["x"])
            x = []
            y = []
            for j in range(n_targets):
                # Count how many times this target was clicked.
                tar_clicks = numpy.sum(( \
                    (self.raw[ppname]["x"] == self._task["target"]["x"][j]) & \
                    (self.raw[ppname]["y"] == self._task["target"]["y"][j]) \
                    ).astype(int))
                if tar_clicks == 0:
                    self.data["omissions"][i] += 1
                else:
                    x.append(self._task["target"]["x"][j])
                    y.append(self._task["target"]["y"][j])
                if tar_clicks > 1:
                    self.data["revisits_tot"][i] += (tar_clicks - 1)

            # Compute centre of cancellation.
            xbound= (numpy.nanmin(self._task["target"]["x"]), \
                numpy.nanmax(self._task["target"]["x"]))
            ybound = (numpy.nanmin(self._task["target"]["y"]), \
                numpy.nanmax(self._task["target"]["y"]))
            fieldsize = (xbound[1]-xbound[0], ybound[1]-ybound[0])
            self.data["CoC_hor"][i] = (numpy.nanmean(x) - xbound[0] \
                - fieldsize[0]/2.0) / (fieldsize[0]/2.0)
            self.data["CoC_ver"][i] = (numpy.nanmean(y) - ybound[0] \
                - fieldsize[1]/2.0) / (fieldsize[1]/2.0)

            # Compute the number of immediate revisits.
            # Immediate revisits are characterised by the lack of a difference
            # in coordinates of the current and the previous click.
            sel = self.raw[ppname]["stimulus"] == "target"
            xd = numpy.diff(self.raw[ppname]["x"][sel])
            yd = numpy.diff(self.raw[ppname]["y"][sel])
            self.data["revisits_imm"][i] = numpy.sum((xd==0) & (yd==0))

            # Compute the number of delayed revisits.
            self.data["revisits_del"][i] = self.data["revisits_tot"][i] \
                - self.data["revisits_imm"][i]
            
            # Compute the total path length.
            self.data["pathlength"][i] = numpy.nansum(numpy.sqrt(xd**2 + yd**2))

            # Compute the average and standardised inter-cancellation distances.
            self.data["interdist"][i] = numpy.nanmean(numpy.sqrt(xd**2 + yd**2))
            # Compute the mean distance between all targets.
            mean_tar_dist = 0.0
            for j in range(n_targets):
                # Get the distance between the current and all other targets.
                td = numpy.sqrt( \
                    (self._task["target"]["x"] \
                    - self._task["target"]["x"][j])**2 \
                    + (self._task["target"]["y"] \
                    - self._task["target"]["y"][j])**2)
                # Find the smallest distance (but ignore the one distance that
                # is 0, as this is the distance between the target and itself).
                mean_tar_dist += numpy.nanmin(td[td>0])
            # Average the minimal target distances.
            mean_tar_dist /= float(n_targets)
            # Divide the mean interdistance by the mean distance between each
            # target and all other targets.
            self.data["interdist_stand"][i] = self.data["interdist"][i] / mean_tar_dist

            # Compute the average inter-cancellation time.
            sel = self.raw[ppname]["stimulus"] == "target"
            self.data["intertime"][i] = numpy.nanmedian(numpy.diff( \
                self.raw[ppname]["time"][sel]))

            # Calculate the Q score.
            # Q = (n_correct / total_targets) * (n_correct / total_time)
            # Only compute this if the time of the final click is not 0.
            if self.raw[ppname]["time"][-1] > 0:
                n_correct = float(n_targets - self.data["omissions"][i])
                self.data["Qscore"][i] = (n_correct / float(n_targets)) \
                    * (n_correct / float(self.raw[ppname]["time"][-1]))

            # Calculate the mean and standardised inter-cancellation angles.
            # Use the vertical distances to compute the inter-click angles,
            # but only those associated with a Euclidean distances > 0 (others
            #  are immediate revisits).
            d = numpy.sqrt(xd**2 + yd**2)
            sel = d > 0
            a = numpy.rad2deg(numpy.arcsin(numpy.abs(yd[sel]) / d[sel]))
            self.data["angle_mean"][i] = numpy.nanmean(a)
            self.data["angle_stand"][i] = numpy.nanmean(numpy.abs( \
                ((a[a>=0] / 90.0) * 2.0) - 1.0))

            # Calculate the best R. (Note that we do include distractor clicks
            # here too, as they constitute parts of the path.)
            rank = numpy.arange(1, self.data["n_stimuli"][i]+1, 1.0)
            hR = abs(pearsonr(rank, self.raw[ppname]["x"])[0])
            vR = abs(pearsonr(rank, self.raw[ppname]["y"])[0])
            self.data["bestR"][i] = max(hR, vR)

            # Calculate the intersection rate.
            self.data["intersect_tot"][i] = 0
            # Loop through all lines between.
            for j in range(0, int(self.data["n_stimuli"][i])-1):
                for k in range(j+1, int(self.data["n_stimuli"][i])-1):
                    line1 = ( \
                        (self.raw[ppname]["x"][j], self.raw[ppname]["y"][j]), \
                        (self.raw[ppname]["x"][j+1], self.raw[ppname]["y"][j+1]))
                    line2 = ( \
                        (self.raw[ppname]["x"][k], self.raw[ppname]["y"][k]), \
                        (self.raw[ppname]["x"][k+1], self.raw[ppname]["y"][k+1]))
                    # Find out if the lines intersect.
                    intersection = self._check_intersection(line1, line2)
                    if intersection:
                        self.data["intersect_tot"][i] += 1
            self.data["intersect_rate"][i] = float(self.data["intersect_tot"][i]) \
                / float(self.data["n_stimuli"][i] - self.data["revisits_imm"][i])

            # Calculate the first cancellation.
            self.data["first_x"][i] = self.raw[ppname]["x"][0]
            self.data["first_y"][i] = self.raw[ppname]["y"][0]
    
    def _check_intersection(self, line1, line2):
    
        """Checks if the passed lines intersect, and returns the coordinates
        of the intersection, by applying Cramer's rule; NOTE: only checks for
        intersections in the domain of each line!
        NOTE: Borrowed this function from CancellationTools, original here:
        https://github.com/esdalmaijer/CancellationTools/blob/master/libcancellation/libhelper.py#L157
        
        Arguments
        
        line1           -   List. Two (x,y) coordinate tuples, one for the
                            start and another for the end coordinates of a
                            line, for example [(1,1),(5,5)
        line2           -   List. Two (x,y) coordinate tuples, one for the
                            start and another for the end coordinates of a
                            line, for example [(1,1),(5,5)
        
        Returns

        intersect       -   Tuple. (x,y) coordinate of the intersection, or
                            None when no intersection was found.
        """
        
        # Convenience renaming of points in the two lines.
        p11, p12 = line1
        p21, p22 = line2

        # Convert values to floats.
        p11 = map(float, p11)
        p12 = map(float, p12)
        p21 = map(float, p21)
        p22 = map(float, p22)
    
        # Coefficients of the line equations.
        A = [p11[1]-p12[1], p21[1]-p22[1]]
        B = [p12[0]-p11[0], p22[0]-p21[0]]
        C = [-1 * (p11[0]*p12[1] - p12[0]*p11[1]),
            -1 * (p21[0]*p22[1] - p22[0]*p21[1])]
        
        # Compute the determinant.
        D  = A[0]*B[1] - B[0]*A[1]
        Dx = C[0]*B[1] - B[0]*C[1]
        Dy = A[0]*C[1] - C[0]*A[1]
            
        # Check if there is an intersection, and return None if there wasn't.
        if D != 0:
            intersect = (Dx/D, Dy/D)
        else:
            return None
        
        # Check if the intersection is in the domain of both lines.
        if min(p11[0],p12[0]) < intersect[0] < max(p11[0],p12[0]) \
            and min(p11[1],p12[1]) < intersect[1] < max(p11[1],p12[1]) \
            and min(p21[0],p22[0]) < intersect[0] < max(p21[0],p22[0]) \
            and min(p21[1],p22[1]) < intersect[1] < max(p21[1],p22[1]):
            return intersect
        # If the intersection was outside of the domain, return None.
        else:
            return None
